{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a machine learning classifier to classify different names based on their genders in python using the scikit learn library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set used for this process contains a huge list of universal names and the respective genders. The list is multi-national so as to prevent specificity and promote generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the data I used already had the 'gender' part labelled with numeric values, with '1' for a male and a '0' for a female.\n",
    "Also, on more exploration I found that the data had some names labelled with a value '3'. At first I thought these names might be unisex like 'Jaskirat' or 'Micky' but on further investigation I found it not to be true, so I had to remove those instances from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gender_refine-csv.csv')\n",
    "del df['score']\n",
    "df.head()\n",
    "df_temp = df\n",
    "df_temp = df_temp[df_temp.gender != 3]\n",
    "# encoded all male values with 1 and female values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one may wonder how do text and machine learning work with each other. Well, the scikit learn library provides a way to do that.\n",
    "Each word is coded as vector of numbers, these vectors might signify the occurence of each character, or some other feature.\n",
    "You can learn more about these methods here - [Text and Machine Learning](http://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "pre_feature = df_temp['name']\n",
    "X = cv.fit_transform(pre_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While writing this kernel, I had just started with machine learning so I couldn't tell just by looking at the type of data that which classifier would do better. So I intend to try most of the classifiers I know, and compare their results and then finally save the model with the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll test different classifiers in the following order -\n",
    "* Naive Bayes Classifier\n",
    "* Support Vector Machine\n",
    "* Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the GridSearchCV method to tune the hyperparameters to get the best results out of each model.\n",
    "You can read more about GridSearch here - [GridSearchCV](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Y = df_temp['gender']\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used 70% of my data to train the model and the rest 30% of the data to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6150403375238747"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, the MultinomialNB did quite a bad job here, 61% of accuracy wasn't something that I was looking for but still we have 2 more classifiers to go. \n",
    "Let's see where we can take this score from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a SVC the hyperparameters play an important role, so unlike the MultinomialNB, I would use the GridSearchCV here to get the best results.\n",
    "(*note* *that this doesn't mean that hyperparameters in a MultinomialNB are useless*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, i tried to run , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  clf = SVC()\n",
    "#  parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "#                     'C': [0.01,0.1,1,10,100,1000]},\n",
    "#                    {'kernel': ['sigmoid'], 'gamma': [1e-1, 1e-2, 1, 5, 10],\n",
    "#                    'C': [0.01,0.1,1,10,100,1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [0.01,0.1,1,10,100,1000]}]\n",
    "#  g_search = GridSearchCV(estimator= clf, param_grid = parameters, scoring= 'accuracy', cv = 5)\n",
    "#  g_search = g_search.fit(features_train, labels_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which I later realized that was too much of processing for this kernel. I got exit code 137 twice. \n",
    "So I thought of slicing the data by a significant factor,\n",
    "and then choosing the best parameters to train my whole data.\n",
    "I know this isn't a great practice but I  in had to compromise for some loss generality over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters gave the best result on my local machine for random 20,000 observations. {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}.\n",
    "And saved the trained classifier in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# clf = joblib.load('../input/name_to_gender_svm_pickle.pkl')\n",
    "# print(clf.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the SVM didn't give the best result for this case, now for the decision tree classifier we will build a custom function for feature analysis, this function will work on the following analogy, \n",
    "* Most of the female names have a vowel at their end, mostly 'A' or 'E' .\n",
    "* Most of the male names have a consonant at their end. (Not always)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'third_last': 'ham', 'third': 'shu', 'second_last': 'am', 'first': 's', 'last': 'm', 'second': 'sh'}\n",
      " {'third_last': 'kit', 'third': 'ank', 'second_last': 'it', 'first': 'a', 'last': 't', 'second': 'an'}\n",
      " {'third_last': 'esh', 'third': 'som', 'second_last': 'sh', 'first': 's', 'last': 'h', 'second': 'so'}\n",
      " {'third_last': 'hek', 'third': 'abh', 'second_last': 'ek', 'first': 'a', 'last': 'k', 'second': 'ab'}]\n"
     ]
    }
   ],
   "source": [
    "def pattern(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'first' : name[0],\n",
    "        'second' : name[0:2],\n",
    "        'third' : name[0:3], \n",
    "        'last' : name[-1],\n",
    "        'second_last' : name[-2:], \n",
    "        'third_last' : name[-3:], \n",
    "    }\n",
    "pattern = np.vectorize(pattern)\n",
    "print(pattern([\"shubham\", \"ankit\", \"somesh\", \"abhishek\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = pattern(df_temp['name']) \n",
    "Y_labels = df_temp['gender']\n",
    "X_train, X_test,  Y_train, Y_test = train_test_split(X_features, Y_labels, test_size = 0.33, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first=a',\n",
       " 'first=s',\n",
       " 'last=h',\n",
       " 'last=k',\n",
       " 'last=m',\n",
       " 'last=t',\n",
       " 'second=ab',\n",
       " 'second=an',\n",
       " 'second=sh',\n",
       " 'second=so',\n",
       " 'second_last=am',\n",
       " 'second_last=ek',\n",
       " 'second_last=it',\n",
       " 'second_last=sh',\n",
       " 'third=abh',\n",
       " 'third=ank',\n",
       " 'third=shu',\n",
       " 'third=som',\n",
       " 'third_last=esh',\n",
       " 'third_last=ham',\n",
       " 'third_last=hek',\n",
       " 'third_last=kit']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer \n",
    "sample = pattern([\"shubham\", \"ankit\", \"somesh\", \"abhishek\"]) \n",
    "dv = DictVectorizer()\n",
    "dv.fit(sample)\n",
    "transformed = dv.transform(sample) \n",
    "# print(transformed)\n",
    "dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852333687511338\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer() \n",
    "dv.fit_transform(X_train) \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier() \n",
    "trans_feat = dv.transform(X_train) \n",
    "clf.fit(trans_feat, Y_train) \n",
    "print(clf.score(dv.transform(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by using the decision tree classifier and a custom function for feature generation we have achieved a score of 85.2. \n",
    "Now, we can try the features extracted by the custom function on other 2 classifiers and see how the results differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451810195143442\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(trans_feat, Y_train) \n",
    "print(clf.score(dv.transform(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84.5 with the MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
